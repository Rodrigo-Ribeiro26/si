{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 8: Adiciona o método randomized_search_cv.\n",
    "#### O método randomized_search_cv implementa uma estratégia de otimização de parâmetros de usando Nº combinações aleatórias. O randomized_search_cv avalia apenas um conjunto aleatório de parâmetros retirados de uma distribuição ou conjunto de valores possíveis.\n",
    "#### 8.1) Considera a estrutura e algoritmo do randomized_search_cv apresentados nos slides seguintes\n",
    "##### Check randomized_search_cv.py\n",
    "#### 8.2) Valida a tua implementação seguindo o protocolo:\n",
    "##### 1. Usa o dataset breast-bin.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rodri\\Desktop\\Mestrado\\SIB\\si\\src\n"
     ]
    }
   ],
   "source": [
    "cd src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from si.io.CSV import read_csv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from si.model_selection.cross_validate import cross_validate\n",
    "from si.model_selection.grid_search import grid_search_cv\n",
    "from si.model_selection.randomized_search_cv import randomized_search_cv\n",
    "from si.linear_model.logistic_regression import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_breast = read_csv(\"C:/Users/rodri/Desktop/Mestrado/SIB/si/datasets/breast-bin.csv\", features=True, label=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Usa o sklearn.preprocessing.StandardScaler para standardizar os dataset.\n",
    "###### breast_dataset.X = StandardScaler().fit_transform(breast_dataset.X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_breast.X = StandardScaler().fit_transform(data_breast.X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Cria o modelo LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Realiza uma procura aleatória com as seguintes distribuições de parâmetros:\n",
    "###### • l2_penalty: distribuição entre 1 e 10 com 10 intervalos iguais (e.g., np.linspace(1, 10, 10))\n",
    "###### • alpha: distribuição entre 0.001 e 0.0001 com 100 intervalos iguais (e.g., np.linspace(0.001, 0.0001, 100))\n",
    "###### • max_iter: distribuição entre 1000 e 2000 com 200 intervalos iguais (e.g., np.linspace(1000, 2000, 200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m lg_model_parameters \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39ml2_penalty\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mlinspace(\u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m10\u001b[39m),\n\u001b[0;32m      2\u001b[0m              \u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mlinspace(\u001b[39m0.001\u001b[39m, \u001b[39m0.0001\u001b[39m, \u001b[39m100\u001b[39m),\n\u001b[0;32m      3\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mmax_iter\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mlinspace(\u001b[39m1000\u001b[39m, \u001b[39m2000\u001b[39m, \u001b[39m200\u001b[39m)}\n\u001b[1;32m----> 5\u001b[0m scores \u001b[39m=\u001b[39m randomized_search_cv(logistic_model, data_breast, lg_model_parameters, cv\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m scores\n",
      "File \u001b[1;32mc:\\Users\\rodri\\Desktop\\Mestrado\\SIB\\si\\src\\si\\model_selection\\randomized_search_cv.py:37\u001b[0m, in \u001b[0;36mrandomized_search_cv\u001b[1;34m(model, dataset, parameter_distribution, scoring, cv, test_size, n_iter)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[39msetattr\u001b[39m(model, parameter, value)\n\u001b[0;32m     36\u001b[0m \u001b[39m# get scores from cross validation\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m score \u001b[39m=\u001b[39m cross_validate(model\u001b[39m=\u001b[39;49mmodel, dataset\u001b[39m=\u001b[39;49mdataset, scoring\u001b[39m=\u001b[39;49mscoring, cv\u001b[39m=\u001b[39;49mcv, test_size\u001b[39m=\u001b[39;49mtest_size)\n\u001b[0;32m     39\u001b[0m \u001b[39m# append everything to dictionary for return\u001b[39;00m\n\u001b[0;32m     40\u001b[0m scores[\u001b[39m\"\u001b[39m\u001b[39mparameters\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(parameters)\n",
      "File \u001b[1;32mc:\\Users\\rodri\\Desktop\\Mestrado\\SIB\\si\\src\\si\\model_selection\\cross_validate.py:56\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(model, dataset, scoring, cv, test_size)\u001b[0m\n\u001b[0;32m     53\u001b[0m train, test \u001b[39m=\u001b[39m train_test_split(dataset\u001b[39m=\u001b[39mdataset, test_size\u001b[39m=\u001b[39mtest_size, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m     55\u001b[0m \u001b[39m# fit the model on the train set\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m model\u001b[39m.\u001b[39;49mfit(train)\n\u001b[0;32m     58\u001b[0m \u001b[39m# score the model on the test set\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39mif\u001b[39;00m scoring \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m     \u001b[39m# store the train score\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rodri\\Desktop\\Mestrado\\SIB\\si\\src\\si\\linear_model\\logistic_regression.py:78\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39m# gradient descent\u001b[39;00m\n\u001b[0;32m     77\u001b[0m threshold \u001b[39m=\u001b[39m \u001b[39m0.0001\u001b[39m  \u001b[39m# No caso do LogisticRegression, o critério de paragem deve ser uma diferença inferior a 0.0001.\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter):\n\u001b[0;32m     79\u001b[0m     \n\u001b[0;32m     80\u001b[0m     \u001b[39m# Durante as iterações do Gradient Descent, computa a função de custo (self.cost(dataset)) e armazena o resultado no dicionário cost_history.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcost_history[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcost(dataset\u001b[39m=\u001b[39mdataset)\n\u001b[0;32m     83\u001b[0m     \u001b[39m# Quando a diferença entre o custo da iteração anterior e o custo da iteração atual for inferior a um determinado valor deves parar o Gradient Descent.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "lg_model_parameters = {'l2_penalty': np.linspace(1, 10, 10),\n",
    "             'alpha': np.linspace(0.001, 0.0001, 100),\n",
    "            'max_iter': np.linspace(1000, 2000, 200)}\n",
    "\n",
    "scores = randomized_search_cv(logistic_model, data_breast, lg_model_parameters, cv=3)\n",
    "scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Podes usar n_iter de 10 e 3 folds para o cross_validate.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Quais os scores obtidos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e5b5b920195072d4a4eec1d5ff9e5f87252d2725e2a57da6939cd4fcd91d4cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
